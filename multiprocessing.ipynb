{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LwHphyYT2lo5"
   },
   "source": [
    "# Multiprocessing in Python\n",
    "\n",
    "Introduction to using multiple processes in Python with help of multiprocessing library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theorethical introduction\n",
    "\n",
    "### Processes and threads\n",
    "\n",
    "- **Process** is an execution context: binary instructions, memory, resources.\n",
    "- **Thread** in a unit of execution, has virtualized processor. \n",
    "- Process has at least one thread, can have many.\n",
    "- Multiple threads share resources in a context of one process.\n",
    "- Processes run in a different address spaces.\n",
    "\n",
    "> **Important note:** There is no multicore multithreading in python!\n",
    "\n",
    "\n",
    "### Processes and threads in Python\n",
    "  \n",
    "\n",
    "\n",
    "| Process                                                                | Thread                                                          |\n",
    "|------------------------------------------------------------------------|-----------------------------------------------------------------|\n",
    "|- can run in parallel in Python                                         |- can run only concurrently in Python (GIL) - no multicore       |\n",
    "|- separate memory space (easy handling, harder communications - IPC)    |- shared memory space (hard management, easy communication)      |\n",
    "|- larger memory footprint (usually used in tens - hundreds)             |- lightweight (can be used in hundreds - thousands)              |\n",
    "\n",
    "\n",
    "\n",
    "**Processes are your only option to utilize multiple cores and CPUs in Python**\n",
    "\n",
    "\n",
    "---------\n",
    "> **Important note:** In notebooks use if __name__=='__main__': to wrap multiprocessing code, especially Pools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic usage of multiprocessing library\n",
    "In this example, we create two processes and try to operate on the same list inside of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1520171574376,
     "user": {
      "displayName": "Karol Horosin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100004662707027644040"
     },
     "user_tz": -60
    },
    "id": "RynK6PXb2QPk",
    "outputId": "b5e19014-74a5-4916-e8fb-d08d3a78d0c8"
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def func(some_list):\n",
    "  some_list.append(\"hello\")\n",
    "  print(some_list)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  some_list = ['first']\n",
    "\n",
    "  p1 = mp.Process(target=func, args=(some_list, ))\n",
    "  p2 = mp.Process(target=func, args=(some_list, ))\n",
    "\n",
    "  p1.start()\n",
    "  p2.start()\n",
    "\n",
    "  p1.join()\n",
    "  p2.join()\n",
    "\n",
    "  print(some_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, changes made to the list in the subprocesses are not visible in the main process. This is a result of the fact, that memory is copied on creation of the new process. There are few techniques to actually share information between processes.\n",
    "\n",
    "Let's do something practical before we visit other functinalities of `multiprocessing`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a task for a list of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_thing(num):\n",
    "    return num\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    items = [1, 2, 3, 4, 5]\n",
    "    processes = []\n",
    "    for item in items:\n",
    "        proc = mp.Process(target=same_thing, args=(item, ))\n",
    "        proc.start()\n",
    "        processes.append(proc)\n",
    "    for proc in processes:\n",
    "        proc.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NNqkHpd39NJw"
   },
   "source": [
    "## Multiprocessing pool - where the fun begins\n",
    "Allows for easy offloading of tasks to 'worker processes'.\n",
    "\n",
    "Map functions - keeps order of returned results. If you don't need it, use `imap_unordered` for optimization. You can also run tasks asynchronously with help of apply_async."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 221,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 808,
     "status": "ok",
     "timestamp": 1520361018399,
     "user": {
      "displayName": "Karol Horosin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100004662707027644040"
     },
     "user_tz": -60
    },
    "id": "n0HnYbRP9Vzi",
    "outputId": "6f08970e-3994-4684-ba6f-aa48ae423bd8"
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import multiprocessing as mp\n",
    "\n",
    "def f_sleep(x):\n",
    "    sleep(2)\n",
    "    return x*x\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  \n",
    "  with mp.Pool(processes=7) as pool:  # default number of processes: os.cpu_count()\n",
    "    \n",
    "    print(pool.map(f, range(10)))\n",
    "\n",
    "    for i in pool.imap_unordered(f, range(10)):\n",
    "        print(i)\n",
    "        \n",
    "    \n",
    "    # run tasks asynchronously\n",
    "    tasks = []   \n",
    "    \n",
    "    for i in range(10):\n",
    "        tasks.append(pool.apply_async(f_sleep, args=(i, )))\n",
    "    \n",
    "    # some other code\n",
    "\n",
    "    # timeout if fetching results takes too long\n",
    "    for i in tasks:\n",
    "        print(i.get(timeout=3))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance - mandelbrot set\n",
    "\"Embarassingly parallel problem\". Let's just skim through it to have a proof.\n",
    "\n",
    "### Standard implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import time\n",
    "\n",
    "\n",
    "def mandelbrotCalcRow(yPos, h, w, max_iteration = 1000):\n",
    "    y0 = yPos * (2/float(h)) - 1 #rescale to -1 to 1\n",
    "    row = []\n",
    "    for xPos in range(w):\n",
    "        x0 = xPos * (3.5/float(w)) - 2.5 #rescale to -2.5 to 1\n",
    "        iteration, z = 0, 0 + 0j\n",
    "        c = complex(x0, y0)\n",
    "        while abs(z) < 2 and iteration < max_iteration:\n",
    "            z = z**2 + c\n",
    "            iteration += 1\n",
    "        row.append(iteration)\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "def mandelbrotCalcSet(h, w, max_iteration = 1000):\n",
    "    partialCalcRow = partial(mandelbrotCalcRow, h=h, w=w, max_iteration = max_iteration)\n",
    "    mandelImg = list(map(partialCalcRow, range(h)))\n",
    "    return mandelImg\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    mandelImg = mandelbrotCalcSet(500, 400, 1000)\n",
    "    print(\"Completed in: %s seconds\" % (time.time() - start_time))\n",
    "    \n",
    "    plt.figure(figsize=(10, 6), facecolor='w', edgecolor='k')\n",
    "plt.imshow(mandelImg,  interpolation='nearest', aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel implmentation\n",
    "Let's use a pool of process to caluclate rows in parallel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "def mandelbrotCalcSet(h, w, max_iteration = 1000):\n",
    "\n",
    "    partialCalcRow = partial(mandelbrotCalcRow, h=h, w=w, max_iteration = max_iteration)\n",
    " \n",
    "    pool = mp.Pool(processes=4)\n",
    "    mandelImg = pool.map(partialCalcRow, range(h)) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    " \n",
    "    return mandelImg\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    mandelImg = mandelbrotCalcSet(500, 400, 1000)\n",
    "    print(\"Completed in: %s seconds\" % (time.time() - start_time))\n",
    "    \n",
    "    plt.figure(figsize=(10, 6), facecolor='w', edgecolor='k')\n",
    "    plt.imshow(mandelImg,  interpolation='nearest', aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to achieve a significant speed-up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical example - reading large csv, splitting, processing\n",
    "Code like this was used to process 300GB CSV in a real project.\n",
    "OA: https://github.com/nuada\n",
    "\n",
    "### Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "os.makedirs('in_dir', exist_ok=True)\n",
    "os.makedirs('out_dir', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the file\n",
    "Split input file into chunks. Chunksize should be more like 1e7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    'sepal_length', 'sepal_width', 'petal_length',\n",
    "    'petal_width', 'class_name'\n",
    "]\n",
    "reader = pd.read_table('iris.data.gz', chunksize=100,\n",
    "                       names=column_names, compression='gzip')\n",
    "\n",
    "for chunk_no, chunk in enumerate(reader):\n",
    "    pq.write_table(\n",
    "        pa.Table.from_pandas(chunk),\n",
    "        os.path.join('in_dir', 'iris-{:04d}.parquet'.format(chunk_no)),\n",
    "        compression='snappy'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_work(filename):\n",
    "    chunk = pq.read_table(filename).to_pandas()\n",
    "    # Some processesing ...\n",
    "    pq.write_table(pa.Table.from_pandas(chunk),\n",
    "                   filename.replace('in', 'out'),\n",
    "                   compression='snappy')\n",
    "\n",
    "with mp.Pool() as pool:\n",
    "    pool.map(do_work, glob.glob('in_dir/*.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pq.read_table('out_dir').to_pandas()\n",
    "# Aggregate the results into final report ...\n",
    "df.to_csv('report.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k2nFMcTs8m0d"
   },
   "source": [
    "## Exchanging data between processes\n",
    "\n",
    "### Pipes\n",
    "- objects have to be picklable\n",
    "- pretty slow\n",
    "- objects > 32MB might cause errors\n",
    "- pipe is basically a buffer\n",
    "- data might become corrupted if to processes write to the same end of the pipe at the same time\n",
    "- implemented in os\n",
    "- can be uni- or bi- dirctional\n",
    "\n",
    "In this example we try to send data from the child process to the main process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1520176537071,
     "user": {
      "displayName": "Karol Horosin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100004662707027644040"
     },
     "user_tz": -60
    },
    "id": "Hff-PPjn8ZCH",
    "outputId": "54a5ff87-24fc-4df8-f996-8e07d39461cd"
   },
   "outputs": [],
   "source": [
    "def func(conn):\n",
    "    conn.send(\"Hi there, bud!\")\n",
    "    conn.close()\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  one_end, second_end = mp.Pipe()\n",
    "\n",
    "  for i in range(10):\n",
    "      p = mp.Process(target=func, args=(second_end,))\n",
    "      p.start()\n",
    "      print(one_end.recv())\n",
    "      p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fTdALuPnA69k"
   },
   "source": [
    "### Queue\n",
    "- higher level than pipes, safer\n",
    "- can store python objects\n",
    "- slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 673,
     "status": "ok",
     "timestamp": 1520176522330,
     "user": {
      "displayName": "Karol Horosin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100004662707027644040"
     },
     "user_tz": -60
    },
    "id": "YneOC88XBDQ1",
    "outputId": "2baa0bd1-c7e7-43b9-8c77-375bab711e5e"
   },
   "outputs": [],
   "source": [
    "def func(results):\n",
    "    results.put([\"An answer is 42\"])\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "  results = mp.Queue()\n",
    "\n",
    "  p1 = mp.Process(target=func, args=(results, ))\n",
    "  p1.start()\n",
    "  p1.join()\n",
    "\n",
    "  print(results.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p9tNVc8_8rHG"
   },
   "source": [
    "## Synchronization\n",
    "\n",
    "To ilustrate synchronization mechanisms, we use shared memory explained later in this notebook.\n",
    "\n",
    "### Trivial example\n",
    "Sometimes we want to ensure some resources are not used by multiple processes at the same time. In this example, process are waiting for lock to be released in order not to mix up their output.\n",
    "\n",
    "Other examples: database, files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 641,
     "status": "ok",
     "timestamp": 1520169728588,
     "user": {
      "displayName": "Karol Horosin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100004662707027644040"
     },
     "user_tz": -60
    },
    "id": "WeB51fVf8uXP",
    "outputId": "8a23e52b-b3b6-47eb-dcb1-c7861a3328bf"
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def f(lock, i):\n",
    "    lock.acquire()\n",
    "    try:\n",
    "        print('hello world', i)\n",
    "    finally:\n",
    "        lock.release()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lock = mp.Lock()\n",
    "\n",
    "    for num in range(2):\n",
    "        mp.Process(target=f, args=(lock, num)).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6dNCQ0Yh8uq2"
   },
   "source": [
    "## Sharing state\n",
    "\n",
    "In general, you should design your software to avoid sharing memory between process. If the use case requires it, multiprocessing provides a way to share memory spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dv2YLg5pLgcy"
   },
   "source": [
    "### Shared memory\n",
    "\n",
    "- uses c-like memory representation there are only Arrays and Values.\n",
    "- see multiprocessing.csharedtypes for more\n",
    "- see resources for use with numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 557,
     "status": "ok",
     "timestamp": 1520169822578,
     "user": {
      "displayName": "Karol Horosin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100004662707027644040"
     },
     "user_tz": -60
    },
    "id": "YWg1kFav9XN6",
    "outputId": "226086ed-0c8c-46be-9e4f-0e128ce751ff"
   },
   "outputs": [],
   "source": [
    "\n",
    "def f(n, a, lock):\n",
    "    lock.acquire()\n",
    "    n.value = 3.1415927\n",
    "    for i in range(len(a)):\n",
    "        a[i] = -a[i]\n",
    "    lock.release()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num = mp.Value('d', 0.0)\n",
    "    arr = mp.Array('i', range(10))\n",
    "    lock = mp.Lock()\n",
    "\n",
    "    p = mp.Process(target=f, args=(num, arr, lock))\n",
    "    p.start()\n",
    "    p.join()\n",
    "\n",
    "    print(num.value)\n",
    "    print(arr[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is locking important?\n",
    "\n",
    "Unsupervised access to shared resources may cause unexpected behaviour, such as presented below. In theory, we should add 1 to `num` value 2000 times, resulting in `num` equaling to 2000 and change sign of `arr` array elements 2000 times, leaving them positive. When you run the cell below, you should notice `num` value beeing lower and `arr` elements having different signs. See `Sharing state` below for more information about Value and Array classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "def f(n, a):\n",
    "    n.value += 1;\n",
    "    for i in range(len(a)):\n",
    "        a[i] = -a[i]\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    num = mp.Value('d', 0.0)\n",
    "    arr = mp.Array('i', range(10))\n",
    "\n",
    "    processes = []\n",
    "    \n",
    "    for i in range(1, 101):\n",
    "        p = mp.Process(target=f, args=(num, arr))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "\n",
    "    for proc in processes:\n",
    "        proc.join()\n",
    "\n",
    "    print(num.value)\n",
    "    print(arr[:])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Server process\n",
    "\n",
    "Less performance but can be used with any pickle'able object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Manager\n",
    "\n",
    "def f(d, l):\n",
    "    d[1] = '1'\n",
    "    d['2'] = 2\n",
    "    d[0.25] = None\n",
    "    l.reverse()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Manager() as manager:\n",
    "        d = manager.dict()\n",
    "        l = manager.list(range(10))\n",
    "\n",
    "        p = Process(target=f, args=(d, l))\n",
    "        p.start()\n",
    "        p.join()\n",
    "\n",
    "        print(d)\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lkbLGyfK8Xod"
   },
   "source": [
    "## Resources\n",
    "- Excelent documentation: [python docs](https://docs.python.org/3.6/library/multiprocessing.html)\n",
    "- YouTube playlist [playlist](https://www.youtube.com/watch?v=PJ4t2U15ACo&list=PLeo1K3hjS3uub3PRhdoCTY8BxMKSW7RjN) - good content, bad english\n",
    "- faster communication between processes [http://nanomsg.org/](http://nanomsg.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: npy array from shared memory\n",
    "Idea: [link](http://coding.derkeiler.com/Archive/Python/comp.lang.python/2008-09/msg00937.html)\n",
    "Modyfied to work with the newest versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import numpy, ctypes\n",
    "\n",
    "_ctypes_to_numpy = {\n",
    "    ctypes.c_char : numpy.int8,\n",
    "    ctypes.c_wchar : numpy.int16,\n",
    "    ctypes.c_byte : numpy.int8,\n",
    "    ctypes.c_ubyte : numpy.uint8,\n",
    "    ctypes.c_short : numpy.int16,\n",
    "    ctypes.c_ushort : numpy.uint16,\n",
    "    ctypes.c_int : numpy.int32,\n",
    "    ctypes.c_uint : numpy.int32,\n",
    "    ctypes.c_long : numpy.int32,\n",
    "    ctypes.c_ulong : numpy.int32,\n",
    "    ctypes.c_float : numpy.float32,\n",
    "    ctypes.c_double : numpy.float64\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shmem_as_ndarray( array_or_value ):\n",
    "    obj = array_or_value._obj\n",
    "    buf = obj._wrapper.create_memoryview()\n",
    "    try:\n",
    "        t = _ctypes_to_numpy[type(obj)]\n",
    "        return numpy.frombuffer(buf, dtype=t, count=1)\n",
    "    except KeyError:\n",
    "        t = _ctypes_to_numpy[obj._type_]\n",
    "        return numpy.frombuffer(buf, dtype=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = mp.Array('i', range(10))\n",
    "shmem_as_ndarray(arr)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "multiprocessing.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
